{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\cuvis.ai.examples\\.venv\\Lib\\site-packages\\cuvis\\General.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import glob\n",
    "import cuvis\n",
    "import cuvis_ai\n",
    "import warnings\n",
    "import matplotlib\n",
    "import torchvision.transforms as T\n",
    "from utils import generate_output_gif\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Classification\n",
    "\n",
    "### Objective: Cluster a dataset using unsupervised methods to group similar spectra together in hyperspectral datacubes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: Aquarium\n",
    "\n",
    "In this notebook, we will be using a CUVIS.AI session file (video file) which contains multiple sequential hyperspectral datacubes. You will load the data, and then define a graph which performs spatial and dimensional transforms to the data before clustering the pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we will download a dataset from Google Drive using Cuvis.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../data/cuvis_ai_video\"\n",
    "if not os.path.exists(base_path):\n",
    "    data_down = cuvis_ai.data.PublicDataSets()\n",
    "    data_down.download_dataset(\"Aquarium\", download_path=base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a single measurement from the dataset. We'll need the size of the dataset to make some decisions on how we should transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 275, Height: 290, Channels 51\n"
     ]
    }
   ],
   "source": [
    "# Let's look at a single example\n",
    "cubes = glob.glob(f'{base_path}/*.cu3s')\n",
    "data = cuvis.SessionFile(cubes[0]).get_measurement(0)\n",
    "sample_cube = data.data.get('cube').array\n",
    "waves = data.data.get('cube').wavelength\n",
    "x,y,z = sample_cube.shape\n",
    "print(f'Width: {x}, Height: {y}, Channels {z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset has 51 channels. For machine learning applications, we can apply a transformation of the data to reduce the spectral dimensionality. Let's use Principal Components Analysis (PCA) to reduce our number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_components = 6\n",
    "# Define PCA with n components\n",
    "pca = cuvis_ai.preprocessor.PCA(number_of_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take the output of the PCA and feed it into an unsupervised classifier. We will use a Gaussian Mixture Model with a pre-defined number of classes. When picking the number of classes, you'll want to consider the composition of the images to see how many classes \"naturally\" exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 4\n",
    "# Define a GMM with n components\n",
    "gmm = cuvis_ai.unsupervised.GMM(number_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this simple, two-stage node, we connect them indicating the PCA node will be the entry point for data, which will then flow to the GMM node.\n",
    "\n",
    "*This will throw an initialization warning \"Unsatisfied dimensionality constraint\", but this is expected behavior*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and construct graph\n",
    "graph = cuvis_ai.pipeline.Graph(\"DemoGraph\")\n",
    "graph.add_base_node(pca)\n",
    "graph.add_edge(pca, gmm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuvis.AI has methods for handling large number of datacubes, including our session file which has over 200 images in it. We'll define it as a dataset to pass into the graph.\n",
    "\n",
    "This dataset is *unlabeled*, meaning it only contains the raw hyperspectral datacubes, and not label files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define unlabeled dataset\n",
    "data = cuvis_ai.data.CuvisDataSet(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "As GMM is an unsupervised classifier, we will need to train the model given a subset of the data. The `fit` method takes a number of sample datacubes from our dataloader and uses that to train the graph. Try adjusting the number of training datacubes and observe the impact that has on the training time. We will then use the `forward` method to generate the output results. Tru "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use first four images to fit the data\n",
    "number_of_training_images = 4\n",
    "graph.fit(*data[0:number_of_training_images])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Results\n",
    "\n",
    "Now that we have defined a graph in cuvis.ai, we can use it to classify all the images in dataset. The cells below will generate and display showing the classification applied to the video rendered as a gif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_output_gif(\n",
    "    graph,\n",
    "    data,\n",
    "    base_path,\n",
    "    gif_name=\"gmm_result.gif\",\n",
    "    title=\"Gaussian Mixture Model - 4 Classes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "As you can see from the results above, clustering takes some tuning to identify clustering parameters which yield good performance. cuvis.ai makes several unsupervised classification techniques available to work with hyperspectral data.\n",
    "\n",
    "- K-Means Clustering\n",
    "- Gaussian Mixture Modeling\n",
    "- Mean-Shift Clustering\n",
    "\n",
    "Take a peek at the [source code](https://github.com/cubert-hyperspectral/cuvis.ai/blob/main/cuvis_ai/unsupervised/sklearn_wrapped.py) and try out different classification nodes with the dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
