{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cuvis_ai\n",
    "import cuvis\n",
    "import yaml\n",
    "from EfficientAD_torch_model import EfficientAdModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.transforms import v2\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(s, prefix):\n",
    "    if s.startswith(prefix):\n",
    "        return s[len(prefix):]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF = 'example_train_config.yaml'\n",
    "WEIGHTS = 'EAD_model_0.93_new.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "First we create a cuvis.ai Graph using some the config parameters from our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONF, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "graph = cuvis_ai.pipeline.Graph('EfficientAD_graph')\n",
    "\n",
    "modelNode = cuvis_ai.node.wrap.make_node(EfficientAdModel)(\n",
    "    criterion=torch.nn.NLLLoss, teacher_out_channels=384, model_size='medium', in_channels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "\n",
    "Using some transformation nodes, a pipeline for data pre- and postprocessing is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CenterCrop = cuvis_ai.node.wrap.make_node(v2.CenterCrop)\n",
    "\n",
    "Resize = cuvis_ai.node.wrap.make_node(v2.Resize)\n",
    "\n",
    "Pad = cuvis_ai.node.wrap.make_node(v2.Pad)\n",
    "\n",
    "graph = graph >> CenterCrop((1800, 4300)) >> Resize(\n",
    "    (1050, 2300)) >> modelNode >> Pad(padding=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Load checkpoint\n",
    "\n",
    "We can easily load the model we previously trained using `train.py` into our modelNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(WEIGHTS, weights_only=True)\n",
    "\n",
    "state_dict = {remove_prefix(\n",
    "    k, 'model.'): v for k, v in checkpoint['state_dict'].items()}\n",
    "\n",
    "modelNode.model.load_state_dict(state_dict)\n",
    "modelNode.initialized = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Save cuvis.ai graph\n",
    "\n",
    "When saving the graph to disk, the whole pipeline and model code will be saved as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.save_to_file('effAD_cuvis.ai')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Load cuvis.ai graph from file\n",
    "\n",
    "We can now load the zip file again into any project without having to worry about the model class being available there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = cuvis_ai.pipeline.Graph.load_from_file(\n",
    "    'effAD_cuvis.ai.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Infer one cube\n",
    "\n",
    "Using the forward function of our graph we can now easily infer any cubert SessionFile that has the same dimensions as the ones we trained our model with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESU = './bedding_dataset/exported/val/20250310_151530_frame_102_ok_nok_rdx_rwx.cu3s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1\n",
    "input_mesu = cuvis.SessionFile(str(MESU)).get_measurement(0)\n",
    "input_data = input_mesu.data[\"cube\"].array\n",
    "normalized_data = (input_data - config[\"mean\"]) / config[\"std\"]\n",
    "normalized_data = np.expand_dims(normalized_data, 0)\n",
    "normalized_data = normalized_data.astype(np.float32)\n",
    "output = loaded.forward(normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Display the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"input SWIR\", cv.resize(cv.normalize(input_data[:, :, 3:], None, 0, 255, cv.NORM_MINMAX, 0), (1000, 500)))\n",
    "cv.imshow(\"input RGB\", cv.resize(cv.normalize(input_data[:, :, :3], None, 0, 255, cv.NORM_MINMAX, 0), (1000, 500)))\n",
    "cv.imshow(\"output\", cv.resize(cv.normalize(output[0], None, 255, 0, cv.NORM_MINMAX, 0), (1000, 500)))\n",
    "\n",
    "cv.waitKey(-1)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cubert_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
