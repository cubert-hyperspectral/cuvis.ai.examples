{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-19T12:58:31.188308Z",
     "start_time": "2025-03-19T12:58:28.258964Z"
    }
   },
   "source": [
    "import cuvis_ai\n",
    "import cuvis\n",
    "import yaml\n",
    "from EfficientAD_torch_model import EfficientAdModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.transforms import v2\n",
    "import cv2 as cv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T12:58:31.200826Z",
     "start_time": "2025-03-19T12:58:31.197683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_prefix(s, prefix):\n",
    "    if s.startswith(prefix):\n",
    "        return s[len(prefix):]\n",
    "    return s"
   ],
   "id": "1b5fb739da861cd4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T12:58:31.211005Z",
     "start_time": "2025-03-19T12:58:31.202957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CONF = 'example_train_config.yaml'\n",
    "WEIGHTS = 'EAD_model_0.81.ckpt'"
   ],
   "id": "73f2f23c6836e5da",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Model\n",
    "\n",
    "First we create a cuvis.ai Graph using some the config parameters from our training."
   ],
   "id": "23026b39ed6a9c69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T12:58:33.864513Z",
     "start_time": "2025-03-19T12:58:31.214404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(CONF, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "graph = cuvis_ai.pipeline.Graph('EfficientAD_graph')\n",
    "\n",
    "modelNode = cuvis_ai.node.wrap.make_node(EfficientAdModel)(\n",
    "    criterion=torch.nn.NLLLoss, teacher_out_channels=384, model_size='medium', in_channels=6)"
   ],
   "id": "58fd8c00e9eb0ebc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create Pipeline\n",
    "\n",
    "Using some transformation nodes, a pipeline for data pre- and postprocessing is created"
   ],
   "id": "def844a2a1ddbdc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T12:58:33.934469Z",
     "start_time": "2025-03-19T12:58:33.929994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CenterCrop = cuvis_ai.node.wrap.make_node(v2.CenterCrop)\n",
    "\n",
    "Resize = cuvis_ai.node.wrap.make_node(v2.Resize)\n",
    "\n",
    "Pad = cuvis_ai.node.wrap.make_node(v2.Pad)\n",
    "\n",
    "graph = graph >> CenterCrop((1800, 4300)) >> Resize(\n",
    "    (1050, 2300)) >> modelNode >> Pad(padding=150)"
   ],
   "id": "2b9ada91dbe666eb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load checkpoint\n",
    "\n",
    "We can easily load the model we previously trained using `train.py` into our modelNode"
   ],
   "id": "5b17724d22634323"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T12:58:34.118391Z",
     "start_time": "2025-03-19T12:58:33.938955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint = torch.load(WEIGHTS, weights_only=True)\n",
    "\n",
    "state_dict = {remove_prefix(\n",
    "    k, 'model.'): v for k, v in checkpoint['state_dict'].items()}\n",
    "\n",
    "modelNode.model.load_state_dict(state_dict)\n",
    "modelNode.initialized = True"
   ],
   "id": "3563ff7ba6821304",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save cuvis.ai graph\n",
    "\n",
    "When saving the graph to disk, the whole pipeline and model code will be saved as well."
   ],
   "id": "a7e5981b7a394181"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T12:58:38.636778Z",
     "start_time": "2025-03-19T12:58:34.297069Z"
    }
   },
   "cell_type": "code",
   "source": "graph.save_to_file('effAD_cuvis.ai')",
   "id": "46b6f86d1f40b0c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find class 'self'\n",
      "Cant find class 'p_dic'\n",
      "Cant find class 'super'\n",
      "Cant find class 'self'\n",
      "Cant find class 'x'\n",
      "Cant find class 'any'\n",
      "Cant find class 'super'\n",
      "Cant find class 'super'\n",
      "Cant find class 'self'\n",
      "Cant find class 'x'\n",
      "Cant find class 'ValueError'\n",
      "Cant find class 'value'\n",
      "Cant find class 'batch'\n",
      "Cant find class 'super'\n",
      "Cant find class 'super'\n",
      "Cant find class 'self'\n",
      "Cant find class 'super'\n",
      "Cant find class 'self'\n",
      "Cant find class 'self'\n",
      "Cant find class 'x'\n",
      "Project saved to effAD_cuvis.ai\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load cuvis.ai graph from file\n",
    "\n",
    "We can now load the zip file again into any project without having to worry about the model class being available there."
   ],
   "id": "41624fbd049d1bee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T12:58:39.497642Z",
     "start_time": "2025-03-19T12:58:38.672297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaded = cuvis_ai.pipeline.Graph.load_from_file(\n",
    "    'effAD_cuvis.ai.zip')"
   ],
   "id": "47860174e9d2e7a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: module__in_channels, module__model_size, module__teacher_out_channels.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Infer one cube\n",
    "\n",
    "Using the forward function of our graph we can now easily infer any cubert SessionFile that has the same dimensions as the ones we trained our model with. "
   ],
   "id": "4ca31c8920cb585f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T13:44:58.282899Z",
     "start_time": "2025-03-19T13:44:58.275390Z"
    }
   },
   "cell_type": "code",
   "source": "MESU = 'D:/bedding_dataset/exported/val/20250311_105414_frame_38_ok_nok_rdx_rwx.cu3s'",
   "id": "bbd293a1c94cb51e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T13:44:58.366888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_samples = 1\n",
    "input_mesu = cuvis.SessionFile(str(MESU)).get_measurement(0)\n",
    "input_data = input_mesu.data[\"cube\"].array\n",
    "normalized_data = (input_data - config[\"mean\"]) / config[\"std\"]\n",
    "normalized_data = np.expand_dims(normalized_data, 0)\n",
    "normalized_data = normalized_data.astype(np.float32)\n",
    "output = loaded.forward(normalized_data)"
   ],
   "id": "48b56edda397f072",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m normalized_data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(normalized_data, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      6\u001B[0m normalized_data \u001B[38;5;241m=\u001B[39m normalized_data\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m----> 7\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mloaded\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnormalized_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai\\cuvis_ai\\pipeline\\graph.py:377\u001B[0m, in \u001B[0;36mGraph.forward\u001B[1;34m(self, X, Y, M, backend)\u001B[0m\n\u001B[0;32m    375\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    376\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown Backend\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 377\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mM\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai\\cuvis_ai\\pipeline\\executor.py:49\u001B[0m, in \u001B[0;36mMemoryExecutor.forward\u001B[1;34m(self, X, Y, M)\u001B[0m\n\u001B[0;32m     45\u001B[0m intermediary[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point], intermediary_labels[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point], intermediary_metas[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_node(\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point], xs, ys, ms)\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m sorted_graph[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[1;32m---> 49\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mintermediary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mintermediary_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mintermediary_metas\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m results \u001B[38;5;241m=\u001B[39m intermediary[sorted_graph[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai\\cuvis_ai\\pipeline\\executor.py:89\u001B[0m, in \u001B[0;36mMemoryExecutor._forward_helper\u001B[1;34m(self, current, intermediary, intermediary_labels, intermediary_metas)\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     87\u001B[0m     use_metas \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 89\u001B[0m intermediary[current], intermediary_labels[current], intermediary_metas[current] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_node\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcurrent\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_prods\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_metas\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_not_needed_anymore(current, intermediary):\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;66;03m# Free memory that is not needed for the current passthrough anymore\u001B[39;00m\n\u001B[0;32m     94\u001B[0m     intermediary\u001B[38;5;241m.\u001B[39mpop(current)\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai\\cuvis_ai\\pipeline\\executor.py:122\u001B[0m, in \u001B[0;36mMemoryExecutor.forward_node\u001B[1;34m(self, node, data, labels, metadata)\u001B[0m\n\u001B[0;32m    120\u001B[0m     out \u001B[38;5;241m=\u001B[39m node\u001B[38;5;241m.\u001B[39mforward(data, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39madditional_meta)\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 122\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, Tuple):\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai\\cuvis_ai\\node\\skorch.py:218\u001B[0m, in \u001B[0;36m_wrap_unsupervised_class.<locals>.SkorchWrappedUnsupervised.forward\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    216\u001B[0m flattened_data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(flattened_data)\n\u001B[0;32m    217\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 218\u001B[0m transformed_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mflattened_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--- \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m seconds ---\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time))\n\u001B[0;32m    220\u001B[0m transformed_data \u001B[38;5;241m=\u001B[39m transformed_data\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai.examples\\venv\\Lib\\site-packages\\skorch\\net.py:1516\u001B[0m, in \u001B[0;36mNeuralNet.forward\u001B[1;34m(self, X, training, device)\u001B[0m\n\u001B[0;32m   1474\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m   1475\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Gather and concatenate the output from forward call with\u001B[39;00m\n\u001B[0;32m   1476\u001B[0m \u001B[38;5;124;03m    input data.\u001B[39;00m\n\u001B[0;32m   1477\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1514\u001B[0m \n\u001B[0;32m   1515\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1516\u001B[0m     y_infer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_iter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1518\u001B[0m     is_multioutput \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(y_infer) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(y_infer[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mtuple\u001B[39m)\n\u001B[0;32m   1519\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_multioutput:\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai.examples\\venv\\Lib\\site-packages\\skorch\\net.py:1471\u001B[0m, in \u001B[0;36mNeuralNet.forward_iter\u001B[1;34m(self, X, training, device)\u001B[0m\n\u001B[0;32m   1469\u001B[0m iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(dataset, training\u001B[38;5;241m=\u001B[39mtraining)\n\u001B[0;32m   1470\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m iterator:\n\u001B[1;32m-> 1471\u001B[0m     yp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluation_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1472\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m to_device(yp, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai.examples\\venv\\Lib\\site-packages\\skorch\\net.py:1164\u001B[0m, in \u001B[0;36mNeuralNet.evaluation_step\u001B[1;34m(self, batch, training)\u001B[0m\n\u001B[0;32m   1162\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(training):\n\u001B[0;32m   1163\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_training(training)\n\u001B[1;32m-> 1164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXi\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai.examples\\venv\\Lib\\site-packages\\skorch\\net.py:1551\u001B[0m, in \u001B[0;36mNeuralNet.infer\u001B[1;34m(self, x, **fit_params)\u001B[0m\n\u001B[0;32m   1549\u001B[0m     x_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_x_and_fit_params(x, fit_params)\n\u001B[0;32m   1550\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule_(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mx_dict)\n\u001B[1;32m-> 1551\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodule_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai.examples\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\dev\\cuvis.ai.examples\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mC:\\Users\\MDCF0~1.MUE\\AppData\\Local\\Temp\\tmpb4b3mqit\\EfficientAdModel.py:339\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(self, batch, batch_imagenet, normalize, return_all_maps)\u001B[0m\n",
      "File \u001B[1;32mC:\\Users\\MDCF0~1.MUE\\AppData\\Local\\Temp\\tmpb4b3mqit\\EfficientAdModel.py:316\u001B[0m, in \u001B[0;36mis_set\u001B[1;34m(p_dic)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Display the result\n",
   "id": "761d16d182cfa162"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T13:45:00.662307100Z",
     "start_time": "2025-03-19T12:59:10.358571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv.imshow(\"input SWIR\", cv.resize(cv.normalize(input_data[:, :, 3:], None, 0, 255, cv.NORM_MINMAX, 0), (1000, 500)))\n",
    "cv.imshow(\"input RGB\", cv.resize(cv.normalize(input_data[:, :, :3], None, 0, 255, cv.NORM_MINMAX, 0), (1000, 500)))\n",
    "cv.imshow(\"output\", cv.resize(cv.normalize(output[0], None, 255, 0, cv.NORM_MINMAX, 0), (1000, 500)))\n",
    "\n",
    "cv.waitKey(-1)\n",
    "cv.destroyAllWindows()"
   ],
   "id": "70bb920058776cd5",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T10:55:36.314550Z",
     "start_time": "2025-03-18T10:55:36.311510Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aecda0ca90681a30",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
